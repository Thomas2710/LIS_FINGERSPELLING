{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b617750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a41ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press one of the following keys to label the data:\n",
      "'h': Hello\n",
      "'t': Thanks\n",
      "'i': I Love You\n",
      "Selected class: Hello\n",
      "Starting in 5 seconds, prepare gesture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1744673848.416683   52018 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1744673848.426245   52097 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 19.1.1, DRM 3.59, 6.11.0-19-generic)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1744673848.474722   52080 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744673848.528154   52081 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/thomas/.cache/pypoetry/virtualenvs/lis-L4bSUyJ--py3.12/lib/python3.12/site-packages/cv2/qt/plugins\"\n",
      "W0000 00:00:1744673849.327422   52076 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /home/thomas/Desktop/LIS/Third_Lecture/data/h/h_me_0.JPG\n",
      "Saved /home/thomas/Desktop/LIS/Third_Lecture/data/h/h_me_1.JPG\n",
      "Saved /home/thomas/Desktop/LIS/Third_Lecture/data/h/h_me_2.JPG\n",
      "Data collection finished!\n",
      "Selected class: Thanks\n",
      "Starting in 5 seconds, prepare gesture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744673866.608894   52018 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1744673866.614001   52141 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.2.8-1ubuntu1~24.04.1), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 19.1.1, DRM 3.59, 6.11.0-19-generic)\n",
      "W0000 00:00:1744673866.654232   52127 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744673866.691147   52134 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /home/thomas/Desktop/LIS/Third_Lecture/data/t/t_me_0.JPG\n",
      "Saved /home/thomas/Desktop/LIS/Third_Lecture/data/t/t_me_1.JPG\n",
      "Saved /home/thomas/Desktop/LIS/Third_Lecture/data/t/t_me_2.JPG\n",
      "Data collection finished!\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "dirname = 'data'\n",
    "stop = False\n",
    "os.makedirs(os.path.join(os.getcwd(), dirname), exist_ok=True)\n",
    "\n",
    "# Classes (customize this as you like)\n",
    "class_map = {\n",
    "    'h': 'Hello',\n",
    "    't': 'Thanks',\n",
    "    'i': 'I Love You',\n",
    "}\n",
    "\n",
    "# Wait for user input\n",
    "\n",
    "print(\"Press one of the following keys to label the data:\")\n",
    "for key, value in class_map.items():\n",
    "    print(f\"'{key}': {value}\")\n",
    "\n",
    "\n",
    "while not stop:\n",
    "    key = input(\"Enter a key: \").strip().lower()\n",
    "    if key in class_map:\n",
    "        count = 0\n",
    "        print(f\"Selected class: {class_map[key]}\")\n",
    "        print(\"Starting in 5 seconds, prepare gesture...\")\n",
    "        folder_path = os.path.join(os.getcwd(), 'data', str(key))\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        time.sleep(5)\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        with mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7, max_num_hands=1) as hands:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = hands.process(rgb_frame)\n",
    "\n",
    "                if results.multi_hand_landmarks:\n",
    "                    hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                cv2.imshow('Live Feed', frame)\n",
    "\n",
    "                # Wait for key press\n",
    "                key_pressed = cv2.waitKey(1) & 0xFF\n",
    "                if key_pressed == ord('q'):\n",
    "                    break\n",
    "                if key_pressed == ord('s'):\n",
    "                    stop = True\n",
    "                    break\n",
    "                if key_pressed != 255:  # if any other key is pressed\n",
    "                    # ðŸ’¡ Capture a fresh frame at key press\n",
    "                    ret, capture_frame = cap.read()\n",
    "                    if ret:\n",
    "                        capture_frame = cv2.flip(capture_frame, 1)\n",
    "                        filename = os.path.join(folder_path, f\"{str(key)}_me_{count}.JPG\")\n",
    "                        cv2.imwrite(filename, capture_frame)\n",
    "                        print(f\"Saved {filename}\")\n",
    "                        count += 1\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "            \n",
    "        print(\"Data collection finished!\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid key. Please try again.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lis-L4bSUyJ--py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
