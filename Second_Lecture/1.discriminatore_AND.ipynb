{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model to predict logic AND values\n",
    "In this tutorial, we are going to experiment with basic deep learning models, in particular with MultiLayer Perceptron(https://en.wikipedia.org/wiki/).\n",
    "\n",
    "We are going to use a very simple task: the prediction of the logic AND operator.\n",
    "\n",
    "## 1.1 Logical AND Truth Table\n",
    "\n",
    "The logical AND operation (denoted as `A ∧ B`) returns `true` if **both** operands are `true`.\n",
    "\n",
    "\n",
    "| A (I study for the exam) | B (I get enough sleep) | A ∧ B (Result)                           |\n",
    "|--------------------------|--------------------|-------------------------------------------|\n",
    "| false                    | false              | false (neither study nor sleep enough)    |\n",
    "| false                    | true               | false (don't study, but sleep enough)     |\n",
    "| true                     | false              | false (study, but don't sleep enough)     |\n",
    "| true                     | true               | true (study and sleep enough)             |\n",
    "\n",
    "Instead of 'true' and 'false', we can use a series of 0's and 1's.\n",
    "\n",
    "Let:\n",
    "- A = \"I study for the exam\"\n",
    "- B = \"I sleep enough\"\n",
    "- 1 = true\n",
    "- 0 = false\n",
    "\n",
    "| A | B | A ∧ B | Interpretation                          |\n",
    "|---|---|--------|-----------------------------------------|\n",
    "| 0 | 0 |   0    | I don’t study and I don’t sleep enough  |\n",
    "| 0 | 1 |   0    | I don’t study but I sleep enough        |\n",
    "| 1 | 0 |   0    | I study but I don’t sleep enough        |\n",
    "| 1 | 1 |   1    | I study and I sleep enough              |\n",
    "\n",
    "\n",
    "This tutorial consists in, given the dataset of truth values of A and B, predict the AND value in output using a deep learning model.\n",
    "\n",
    "<br><br><hr><br><br>\n",
    "\n",
    "# 1. Modello per prevedere i valori dell'operatore logico AND\n",
    "In questo tutorial, andremo a sperimentare modelli di deep learning di base, in particolare il Percettrone Multistrato (MultiLayer Perceptron) (https://en.wikipedia.org/wiki/).\n",
    "\n",
    "Utilizzeremo un esercizio molto semplice: la previsione dell’operatore logico AND.\n",
    "\n",
    "## 1.1 Tabella di verità dell’AND logico\n",
    "\n",
    "L’operazione logico AND (indicato come `A ∧ B`) restituisce `vero` se **entrambi** gli operandi sono `veri`.\n",
    "\n",
    "| A (Studio per l'esame)  | B (Dormo abbastanza)     | A ∧ B (Risultato)                         |\n",
    "|-------------------------|--------------------------|-------------------------------------------|\n",
    "| falso                   | falso                    | falso (né studio né dormo abbastanza)     |\n",
    "| falso                   | vero                     | falso (non studio, ma dormo abbastanza)   |\n",
    "| vero                    | falso                    | falso (studio, ma non dormo abbastanza)   |\n",
    "| vero                    | vero                     | vero (studio e dormo abbastanza)          |\n",
    "\n",
    "Al posto di 'vero' e 'falso', possiamo usare una sequenza di 0 e 1.\n",
    "\n",
    "Sia:\n",
    "- A = \"Studio per l’esame\"\n",
    "- B = \"Dormo abbastanza\"\n",
    "- 1 = vero\n",
    "- 0 = falso\n",
    "\n",
    "| A | B | A ∧ B | Interpretazione                            |\n",
    "|---|---|--------|--------------------------------------------|\n",
    "| 0 | 0 |   0    | Non studio e non dormo abbastanza          |\n",
    "| 0 | 1 |   0    | Non studio ma dormo abbastanza             |\n",
    "| 1 | 0 |   0    | Studio ma non dormo abbastanza             |\n",
    "| 1 | 1 |   1    | Studio e dormo abbastanza                  |\n",
    "\n",
    "Questo tutorial consiste nel prevedere, dato un dataset con i valori di verità di A e B, il valore di A ∧ B in output usando un modello di deep learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the right libraries\n",
    "<br><hr><br>\n",
    "Cominciamo con l'importare le giuste librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Generate the dataset\n",
    "\n",
    "Create a dataset for the problem. \n",
    "\n",
    "The dataset `X` and the label `y` must be numpy arrays.\n",
    "<hr>\n",
    "\n",
    "## 1.2 Generare il dataset\n",
    "\n",
    "Crea un dataset per il problema.  \n",
    "\n",
    "Il dataset `X` e i valori di riferimento `y` devono essere numpy arrays.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 'Crea qui il numpy array per i dati di input'\n",
    "\n",
    "y = 'Crea qui il numpy array per le etichette'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create the model class\n",
    "\n",
    "Now, we are going to see how to instantiate a deep learning model in Pytorch.\n",
    "\n",
    "PyTorch is an open-source machine learning library that provides flexible tools for building and training deep learning models, with strong support for dynamic computation graphs and GPU acceleration (https://pytorch.org/).\n",
    "\n",
    "A pytorch model extends the `nn.Module` class and must define an `__init__` function to specify and initialize the model’s layers and parameters, and a `forward` function to define the computation that occurs when data passes through the model.\n",
    "<hr>\n",
    "\n",
    "## 1.3 Creare la classe del modello\n",
    "\n",
    "Ora vedremo come istanziare un modello di deep learning in PyTorch.\n",
    "\n",
    "PyTorch è una libreria open-source per il machine learning che fornisce strumenti flessibili per costruire e addestrare modelli di deep learning, con un forte supporto per i grafi computazionali dinamici e l'accelerazione tramite GPU (https://pytorch.org/).\n",
    "\n",
    "Un modello in PyTorch estende la classe `nn.Module` e deve definire una funzione `__init__` per specificare e inizializzare i layer e i parametri del modello, e una funzione `forward` per definire il calcolo che avviene quando i dati passano attraverso il modello.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a single-layer model\n",
    "class ANDClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANDClassifier, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 128)\n",
    "        self.layer2 = nn.Linear(128, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)  # Single neuron\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = torch.sigmoid(x)  # Sigmoid for binary classification\n",
    "        return x\n",
    "    \n",
    "# Initialize the model\n",
    "model = ANDClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the specifics of our model, accessing every parameter it has separately\n",
    "<hr>\n",
    "\n",
    "Possiamo verificare i dettagli del nostro modello accedendo separatamente a ciascun parametro che lo compone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight Parameter containing:\n",
      "tensor([[ 0.6550, -0.2956],\n",
      "        [ 0.5035, -0.5489],\n",
      "        [ 0.7064,  0.5835],\n",
      "        [-0.1190, -0.4109],\n",
      "        [-0.3324,  0.3591],\n",
      "        [ 0.5972, -0.3012],\n",
      "        [ 0.6140, -0.5316],\n",
      "        [ 0.4536,  0.6132],\n",
      "        [-0.2297, -0.5543],\n",
      "        [-0.6236,  0.3674],\n",
      "        [-0.6539,  0.0281],\n",
      "        [ 0.2064,  0.3335],\n",
      "        [ 0.0520,  0.1818],\n",
      "        [-0.0710, -0.3942],\n",
      "        [ 0.4520, -0.2759],\n",
      "        [ 0.5973,  0.5007],\n",
      "        [-0.6283, -0.4864],\n",
      "        [-0.6048, -0.1885],\n",
      "        [ 0.4669, -0.0300],\n",
      "        [-0.2519, -0.0908],\n",
      "        [-0.5515,  0.5316],\n",
      "        [ 0.2860,  0.1859],\n",
      "        [ 0.0093,  0.0990],\n",
      "        [-0.3936,  0.3791],\n",
      "        [-0.6724,  0.6532],\n",
      "        [ 0.4907,  0.3502],\n",
      "        [ 0.3333,  0.3352],\n",
      "        [-0.5291, -0.2876],\n",
      "        [ 0.0463,  0.6214],\n",
      "        [ 0.4683, -0.2174],\n",
      "        [-0.2122, -0.5421],\n",
      "        [-0.0829, -0.3685],\n",
      "        [-0.3763,  0.3427],\n",
      "        [ 0.5299,  0.2332],\n",
      "        [-0.1751, -0.2717],\n",
      "        [-0.6414,  0.4450],\n",
      "        [ 0.1153,  0.7016],\n",
      "        [ 0.4996, -0.6856],\n",
      "        [-0.0651,  0.2511],\n",
      "        [-0.4750,  0.5503],\n",
      "        [-0.0962,  0.6130],\n",
      "        [-0.2502,  0.1403],\n",
      "        [ 0.6280,  0.1613],\n",
      "        [ 0.1710, -0.1865],\n",
      "        [-0.5250, -0.2134],\n",
      "        [-0.5298, -0.6490],\n",
      "        [ 0.2462, -0.6647],\n",
      "        [-0.3697, -0.2996],\n",
      "        [-0.3573,  0.1321],\n",
      "        [ 0.5820,  0.3807],\n",
      "        [-0.5340,  0.6555],\n",
      "        [ 0.4764, -0.1902],\n",
      "        [ 0.3756, -0.4343],\n",
      "        [ 0.2950,  0.1266],\n",
      "        [ 0.7028,  0.1142],\n",
      "        [-0.2759,  0.3419],\n",
      "        [-0.4508,  0.1241],\n",
      "        [ 0.2426,  0.6501],\n",
      "        [ 0.0214,  0.3985],\n",
      "        [-0.3780, -0.1943],\n",
      "        [ 0.5535, -0.2685],\n",
      "        [ 0.3347, -0.5995],\n",
      "        [ 0.4589, -0.0932],\n",
      "        [ 0.4500,  0.2291],\n",
      "        [ 0.5914,  0.0787],\n",
      "        [ 0.6759, -0.2374],\n",
      "        [-0.5789, -0.4943],\n",
      "        [-0.0354,  0.4216],\n",
      "        [-0.2211, -0.2863],\n",
      "        [ 0.2306,  0.1070],\n",
      "        [ 0.3885, -0.1407],\n",
      "        [-0.0405, -0.1043],\n",
      "        [-0.0967, -0.4013],\n",
      "        [-0.0318, -0.1933],\n",
      "        [-0.4849, -0.2889],\n",
      "        [-0.1214, -0.5649],\n",
      "        [-0.3614,  0.5504],\n",
      "        [-0.3572,  0.5167],\n",
      "        [ 0.0707,  0.5559],\n",
      "        [ 0.4151,  0.1269],\n",
      "        [ 0.5935, -0.2642],\n",
      "        [ 0.1666, -0.0160],\n",
      "        [ 0.3248, -0.4379],\n",
      "        [ 0.3045,  0.4831],\n",
      "        [-0.1645,  0.0226],\n",
      "        [-0.3016,  0.6722],\n",
      "        [-0.6729, -0.6880],\n",
      "        [-0.4434,  0.2667],\n",
      "        [ 0.2799,  0.2376],\n",
      "        [ 0.2772,  0.4009],\n",
      "        [-0.3420,  0.1922],\n",
      "        [ 0.4029, -0.0080],\n",
      "        [-0.4627, -0.1630],\n",
      "        [-0.5994, -0.0642],\n",
      "        [ 0.3599,  0.0387],\n",
      "        [-0.0693,  0.4430],\n",
      "        [ 0.3547,  0.1372],\n",
      "        [ 0.6193,  0.4632],\n",
      "        [ 0.5114, -0.6978],\n",
      "        [-0.0611,  0.3396],\n",
      "        [-0.4148, -0.2252],\n",
      "        [-0.6275, -0.3230],\n",
      "        [ 0.4417,  0.0873],\n",
      "        [-0.4206, -0.3432],\n",
      "        [-0.4823, -0.6848],\n",
      "        [ 0.6107, -0.2501],\n",
      "        [ 0.6218, -0.1075],\n",
      "        [ 0.0531, -0.6787],\n",
      "        [ 0.1901,  0.6099],\n",
      "        [-0.3015,  0.2683],\n",
      "        [-0.3745, -0.3200],\n",
      "        [-0.5148,  0.0421],\n",
      "        [-0.5362,  0.2205],\n",
      "        [-0.5009,  0.5503],\n",
      "        [-0.2628,  0.4427],\n",
      "        [-0.6578, -0.6012],\n",
      "        [ 0.4672,  0.5109],\n",
      "        [-0.5423, -0.0607],\n",
      "        [-0.5546, -0.5111],\n",
      "        [-0.3423,  0.0900],\n",
      "        [ 0.5375,  0.4408],\n",
      "        [-0.3782, -0.1873],\n",
      "        [ 0.4711,  0.6925],\n",
      "        [-0.4864,  0.5285],\n",
      "        [-0.3355, -0.2840],\n",
      "        [-0.4445, -0.2988],\n",
      "        [ 0.5044, -0.5758],\n",
      "        [-0.2083, -0.3638]], requires_grad=True)\n",
      "layer1.bias Parameter containing:\n",
      "tensor([ 0.4851,  0.6791, -0.5614, -0.2742, -0.1990,  0.6952, -0.6106,  0.3939,\n",
      "        -0.1263, -0.1486,  0.3783, -0.2292,  0.1850,  0.2798,  0.5848,  0.5906,\n",
      "         0.0582, -0.3642, -0.6891,  0.5845,  0.0404,  0.1271, -0.2576,  0.6084,\n",
      "        -0.0065,  0.0341, -0.5919, -0.0099, -0.3720,  0.5008, -0.6810, -0.4812,\n",
      "         0.3023,  0.5348, -0.1550, -0.5333, -0.1228, -0.5022,  0.5384, -0.5959,\n",
      "         0.2795,  0.5508,  0.0826, -0.2654, -0.1521, -0.2773,  0.3653, -0.4380,\n",
      "         0.5081,  0.0383,  0.4808, -0.5309,  0.1606,  0.3943, -0.3100,  0.2487,\n",
      "        -0.0061,  0.4174,  0.1395, -0.1496, -0.5164, -0.3970,  0.3090,  0.6044,\n",
      "        -0.0007,  0.2121,  0.6598, -0.5031, -0.5942,  0.4069, -0.0116,  0.2021,\n",
      "         0.0289, -0.5267, -0.3605,  0.6819,  0.1292, -0.3909, -0.3463, -0.5950,\n",
      "        -0.6468,  0.5575, -0.1996, -0.4853, -0.4165, -0.5545,  0.0570,  0.4754,\n",
      "        -0.6268, -0.4841, -0.0786, -0.6534,  0.1069,  0.2645,  0.0814,  0.4423,\n",
      "        -0.4430,  0.2032, -0.4126,  0.5720, -0.0231,  0.5405,  0.1912, -0.2640,\n",
      "        -0.5319, -0.3029, -0.2012,  0.2658,  0.2987, -0.6048, -0.1248,  0.2090,\n",
      "        -0.6754, -0.6049,  0.2450,  0.3205, -0.5762,  0.4555, -0.0703,  0.0364,\n",
      "        -0.5276,  0.5057,  0.4151,  0.5449,  0.2049,  0.2155,  0.5334,  0.1490],\n",
      "       requires_grad=True)\n",
      "layer2.weight Parameter containing:\n",
      "tensor([[ 0.0704,  0.0530,  0.0247,  ..., -0.0609,  0.0416,  0.0161],\n",
      "        [ 0.0617,  0.0072,  0.0167,  ...,  0.0240, -0.0406,  0.0674],\n",
      "        [-0.0655, -0.0762, -0.0863,  ..., -0.0173,  0.0074,  0.0591],\n",
      "        ...,\n",
      "        [ 0.0178, -0.0476,  0.0181,  ..., -0.0435, -0.0401, -0.0127],\n",
      "        [ 0.0146, -0.0095, -0.0407,  ..., -0.0849,  0.0316,  0.0807],\n",
      "        [ 0.0110,  0.0847,  0.0015,  ..., -0.0534, -0.0734,  0.0695]],\n",
      "       requires_grad=True)\n",
      "layer2.bias Parameter containing:\n",
      "tensor([-0.0823,  0.0729,  0.0222, -0.0388,  0.0698,  0.0218, -0.0087, -0.0012,\n",
      "         0.0816,  0.0862, -0.0496,  0.0061, -0.0758,  0.0787, -0.0376,  0.0614,\n",
      "         0.0267,  0.0565, -0.0881,  0.0597,  0.0837,  0.0519,  0.0030, -0.0008,\n",
      "        -0.0804, -0.0713,  0.0015, -0.0094, -0.0234, -0.0109, -0.0412, -0.0538],\n",
      "       requires_grad=True)\n",
      "layer3.weight Parameter containing:\n",
      "tensor([[ 0.0177, -0.1642, -0.0688, -0.0286,  0.0269, -0.0575, -0.0567, -0.0376,\n",
      "         -0.1574, -0.0706, -0.1286,  0.0944, -0.0246, -0.0804, -0.0911, -0.0225,\n",
      "         -0.0769, -0.1075,  0.0732,  0.0811,  0.0788, -0.0079, -0.0458,  0.0832,\n",
      "         -0.1339,  0.1358, -0.0052,  0.0856, -0.0010, -0.0611,  0.0390,  0.0799]],\n",
      "       requires_grad=True)\n",
      "layer3.bias Parameter containing:\n",
      "tensor([0.1310], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[43mX\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "output = model(X)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 The training loop\n",
    "Now, we are going to start looking at the training of the model. Training is the process of altering the weights of the model so that the outputs values are more similar to the desired ones.\n",
    "We create two objects, representing:\n",
    "- The loss function\n",
    "- The optimizer\n",
    "\n",
    "### 1.4.1 The loss function\n",
    "A loss function measures how far the model's predictions are from the true values, guiding the learning process during training.\n",
    "\n",
    "### 1.4.2 The optimizer\n",
    "An optimizer is an algorithm that adjusts the model’s parameters based on the loss to help it learn and improve over time.\n",
    "\n",
    "<hr>\n",
    "\n",
    "## 1.4 Il ciclo di addestramento\n",
    "\n",
    "Ora inizieremo a osservare l’addestramento del modello. L’addestramento è il processo di modifica dei pesi del modello affinché i valori in uscita siano sempre più simili a quelli desiderati.  \n",
    "Creiamo due oggetti che rappresentano:\n",
    "- La funzione di perdita (loss function)\n",
    "- L’ottimizzatore\n",
    "\n",
    "### 1.4.1 La funzione di perdita\n",
    "\n",
    "Una funzione di perdita misura quanto le predizioni del modello si discostano dai valori reali, guidando il processo di apprendimento durante l’addestramento.\n",
    "\n",
    "### 1.4.2 L’ottimizzatore\n",
    "\n",
    "Un ottimizzatore è un algoritmo che regola i parametri del modello in base alla perdita, per aiutarlo ad apprendere e migliorare nel tempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The `BCELoss` function in PyTorch is used for binary classification and compares the predicted probability (between 0 and 1) to the true label (0 or 1) using binary cross-entropy\n",
    "\n",
    "- The `Adam` optimizer is an adaptive learning rate method\n",
    "\n",
    "<hr>\n",
    "\n",
    "- La funzione `BCELoss` in PyTorch viene utilizzata per la classificazione binaria e confronta la probabilità predetta (compresa tra 0 e 1) con l’etichetta reale (0 o 1) utilizzando la cross-entropia binaria.\n",
    "\n",
    "- L’ottimizzatore `Adam` è un metodo che sfrutta un rateo di apprendimento adattivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4.3 Running the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0000\n",
      "Epoch [200/1000], Loss: 0.0000\n",
      "Epoch [300/1000], Loss: 0.0000\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the model has been trained. We can print the parameters values again to see if they are different from before\n",
    "\n",
    "<hr>\n",
    "\n",
    "Ora il modello è stato addestrato. Possiamo stampare nuovamente i valori dei parametri per vedere se sono cambiati rispetto a prima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight Parameter containing:\n",
      "tensor([[-0.3198, -0.2834],\n",
      "        [-0.3809, -0.0279],\n",
      "        [-0.0765,  0.2279],\n",
      "        [-0.0739, -1.0362],\n",
      "        [-0.3256, -0.3658],\n",
      "        [ 0.1738,  0.4377],\n",
      "        [ 0.3431, -0.4622],\n",
      "        [-0.1911, -0.3752],\n",
      "        [ 0.3896, -0.7205],\n",
      "        [ 0.8918,  0.7226],\n",
      "        [ 0.0858, -0.5019],\n",
      "        [-0.2679, -0.1474],\n",
      "        [-0.2565, -0.2720],\n",
      "        [ 0.4052, -0.1607],\n",
      "        [-0.4266, -0.6773],\n",
      "        [-0.6299, -0.3413],\n",
      "        [-0.6629, -0.2279],\n",
      "        [-0.5500, -0.2714],\n",
      "        [ 0.0285,  0.1235],\n",
      "        [-0.3957,  0.1670],\n",
      "        [ 0.0483,  0.2819],\n",
      "        [ 0.6448,  0.6872],\n",
      "        [-0.1199, -0.6721],\n",
      "        [-0.0324, -1.0586],\n",
      "        [ 0.9494,  0.5982],\n",
      "        [-0.4483, -0.4471],\n",
      "        [ 0.0801,  0.2273],\n",
      "        [-0.4789, -0.1365],\n",
      "        [ 0.1446, -0.1248],\n",
      "        [-0.2165, -0.3227],\n",
      "        [-0.8656, -0.0437],\n",
      "        [-1.6003,  1.1304],\n",
      "        [ 0.0220, -1.0474],\n",
      "        [-0.4430, -0.0174],\n",
      "        [-0.1760, -0.5573],\n",
      "        [-1.2297,  0.6035],\n",
      "        [ 1.0880,  0.6581],\n",
      "        [ 0.3301,  0.9551],\n",
      "        [-0.1668, -0.1280],\n",
      "        [-0.3931,  0.0400],\n",
      "        [-0.3434, -0.5664],\n",
      "        [-0.4178,  0.0942],\n",
      "        [-0.1291, -0.6297],\n",
      "        [ 0.5457,  0.6029],\n",
      "        [-1.4968,  0.7680],\n",
      "        [ 0.5339, -1.2328],\n",
      "        [-0.1229,  0.0108],\n",
      "        [ 0.7013,  0.9383],\n",
      "        [ 0.3150,  0.1450],\n",
      "        [ 0.0931, -0.8375],\n",
      "        [-1.1046,  0.2937],\n",
      "        [ 0.7404,  0.8085],\n",
      "        [-1.5558,  0.7550],\n",
      "        [-0.2830, -0.4505],\n",
      "        [-0.3300,  0.0343],\n",
      "        [-1.3398,  0.2207],\n",
      "        [-0.3318, -0.8575],\n",
      "        [ 0.2619, -0.3026],\n",
      "        [-0.9053,  0.0680],\n",
      "        [-0.4840, -0.8679],\n",
      "        [-0.1591, -0.9028],\n",
      "        [-0.5814, -0.2621],\n",
      "        [ 0.3181, -1.0275],\n",
      "        [ 0.7145, -0.9032],\n",
      "        [ 0.0391,  0.0432],\n",
      "        [-0.2084, -0.3678],\n",
      "        [-0.6654,  0.2747],\n",
      "        [ 0.9955,  1.0240],\n",
      "        [ 0.8942,  0.9360],\n",
      "        [-0.8282, -0.1495],\n",
      "        [ 0.3698, -1.3828],\n",
      "        [-0.2993, -0.4616],\n",
      "        [ 0.0420,  0.5758],\n",
      "        [-0.2773,  0.4108],\n",
      "        [-1.5616,  0.6143],\n",
      "        [ 0.2678, -0.8903],\n",
      "        [ 0.6177,  1.0410],\n",
      "        [ 0.6031,  0.6047],\n",
      "        [-0.2911, -0.3448],\n",
      "        [-0.1069, -0.7381],\n",
      "        [ 0.3435,  0.3761],\n",
      "        [ 0.7556, -1.2694],\n",
      "        [-0.2985, -0.1618],\n",
      "        [-0.2147, -0.0650],\n",
      "        [ 0.0415, -0.9967],\n",
      "        [-0.7924,  0.3582],\n",
      "        [-0.2037, -0.6084],\n",
      "        [-0.3987, -1.0471],\n",
      "        [-0.2963, -0.2909],\n",
      "        [-0.2489,  0.0534],\n",
      "        [-0.0470, -0.8347],\n",
      "        [-0.6503, -0.5755],\n",
      "        [-0.1938, -0.6132],\n",
      "        [ 0.4268,  0.9068],\n",
      "        [-0.1571, -0.3954],\n",
      "        [-0.3301, -0.5422],\n",
      "        [ 0.0775,  0.3716],\n",
      "        [ 0.1116, -0.0725],\n",
      "        [ 0.1634, -0.5817],\n",
      "        [-0.2827, -0.3145],\n",
      "        [-0.6389,  0.6698],\n",
      "        [-0.2940, -0.1911],\n",
      "        [ 0.3578,  0.0620],\n",
      "        [-0.3800, -0.4574],\n",
      "        [ 0.1411,  0.1756],\n",
      "        [ 0.1128, -1.0744],\n",
      "        [ 0.2339, -1.1171],\n",
      "        [ 0.2219,  0.0065],\n",
      "        [ 1.4922,  1.3100],\n",
      "        [-0.0614, -0.7485],\n",
      "        [-0.6714, -0.1342],\n",
      "        [-0.1659,  0.4800],\n",
      "        [ 0.7599,  0.6000],\n",
      "        [-0.6602,  0.0509],\n",
      "        [ 0.7743,  0.9175],\n",
      "        [-0.3921,  0.5470],\n",
      "        [-0.1783, -0.4087],\n",
      "        [-0.5680, -0.1969],\n",
      "        [ 0.1785, -1.0959],\n",
      "        [ 1.1686,  0.7322],\n",
      "        [-0.3043, -0.9198],\n",
      "        [ 0.3352, -0.9321],\n",
      "        [-0.5500,  0.3907],\n",
      "        [-0.3687, -0.0858],\n",
      "        [-0.6425, -0.3327],\n",
      "        [-0.6099, -0.0722],\n",
      "        [-0.5325, -0.7049],\n",
      "        [-0.1058, -0.0972]], requires_grad=True)\n",
      "layer1.bias Parameter containing:\n",
      "tensor([-7.5669e-01, -6.7118e-01, -1.1330e-01, -1.8488e-01, -7.1820e-01,\n",
      "         1.1778e+00,  6.8020e-01, -6.4080e-01, -5.0179e-01, -4.6528e-01,\n",
      "        -1.1062e+00, -4.3084e-01, -5.7483e-01, -5.3383e-01,  1.0148e+00,\n",
      "        -3.6982e-01,  3.3337e-01,  1.0004e+00, -6.2131e-01, -6.2990e-01,\n",
      "        -1.9241e-01, -6.0821e-01, -1.6421e-01, -7.6411e-02, -4.8101e-01,\n",
      "        -7.2366e-01, -3.4980e-01, -3.7418e-01,  2.2692e-01,  2.5775e-02,\n",
      "        -5.8678e-01,  1.5152e-01, -3.2992e-01,  1.4910e+00, -1.0857e+00,\n",
      "         1.0749e+00, -5.0733e-01, -2.0907e-01, -1.5889e-01,  9.6549e-01,\n",
      "        -6.8899e-01, -1.1937e+00, -6.3497e-01, -3.4914e-01,  5.7081e-01,\n",
      "         1.1981e+00, -5.0544e-01, -1.2589e-01, -6.8604e-01, -7.7885e-02,\n",
      "         1.1953e+00, -2.8156e-01,  6.3410e-01,  7.7568e-01, -5.4607e-01,\n",
      "         3.8620e-01,  1.3644e-01, -1.6252e-01,  8.6720e-01,  6.6771e-01,\n",
      "         5.2908e-01, -6.1351e-01,  7.8053e-02, -5.9374e-02, -2.3655e-01,\n",
      "        -4.8328e-01, -6.2948e-01,  2.5038e-02, -2.8588e-01, -7.4861e-01,\n",
      "         4.7660e-01, -6.9579e-01,  1.5305e+00, -1.8948e-01,  7.6778e-01,\n",
      "        -2.0517e-01, -4.9836e-01, -2.4809e-01, -6.6446e-01, -3.8883e-01,\n",
      "        -9.8687e-02,  1.0035e+00, -7.8146e-01, -8.5811e-02,  5.5248e-01,\n",
      "         2.3131e-04,  6.2552e-01,  6.1660e-03,  4.9830e-02, -4.8731e-02,\n",
      "         4.1428e-01, -9.5088e-02, -2.1488e-02,  1.0617e+00, -3.7487e-01,\n",
      "        -2.8046e-01, -2.9354e-01, -3.8073e-01, -4.5893e-01, -6.3166e-01,\n",
      "        -7.0288e-01, -9.1248e-01, -1.4536e-01,  1.8914e-01, -5.7157e-01,\n",
      "        -2.5213e-01,  5.6332e-01, -5.0332e-01, -3.8316e-03,  3.2797e-01,\n",
      "        -4.4001e-01, -5.4044e-01, -3.1223e-01, -7.0475e-01, -4.7539e-01,\n",
      "        -6.0751e-01, -9.9902e-01, -6.5922e-02,  1.5266e-01, -5.9128e-01,\n",
      "         3.3513e-01, -6.2416e-01, -5.0750e-01, -5.7450e-01, -3.7632e-01,\n",
      "        -3.6394e-01, -1.4462e-01, -2.4728e-01], requires_grad=True)\n",
      "layer2.weight Parameter containing:\n",
      "tensor([[-0.1856, -0.0338, -0.0911,  ..., -0.4517,  0.0749, -0.0499],\n",
      "        [-0.6066,  0.0343,  0.5035,  ..., -0.5440,  0.0848, -0.0396],\n",
      "        [-0.2328, -0.0324, -0.2538,  ...,  0.0104,  0.0076,  0.0364],\n",
      "        ...,\n",
      "        [-0.2491,  0.0699, -0.1230,  ..., -0.0799, -0.0325, -0.0558],\n",
      "        [ 1.1216,  0.0772,  1.4518,  ...,  0.0109, -0.0367, -0.0509],\n",
      "        [-0.3746, -0.0556, -0.3994,  ..., -0.4062, -0.0865,  0.0381]],\n",
      "       requires_grad=True)\n",
      "layer2.bias Parameter containing:\n",
      "tensor([-0.9937, -0.6852,  0.2353, -0.1561, -0.6375,  0.7458, -0.6581, -0.4456,\n",
      "         0.2174, -0.1289, -0.7991, -0.2043,  0.5206, -0.5944, -0.3539,  0.6419,\n",
      "        -0.5586,  0.2999, -0.6743,  0.2641, -0.5471, -0.5180, -0.0820, -0.6765,\n",
      "         0.5433,  0.3535, -0.5211,  0.4011, -0.4415,  0.2342,  0.2335, -0.1815],\n",
      "       requires_grad=True)\n",
      "layer3.weight Parameter containing:\n",
      "tensor([[ 0.4403, -0.5448,  0.0408,  0.1602, -0.5448, -0.8839, -0.4765, -0.3516,\n",
      "         -0.0688, -0.0145,  0.3143,  0.0577, -0.2822, -0.5721, -0.4041, -1.0864,\n",
      "         -0.4896, -0.0825, -0.4858, -0.1135, -0.5976, -0.5231, -0.1417, -0.5916,\n",
      "         -0.9679,  1.0483, -0.5733, -0.1146,  0.4866, -0.0099,  1.3603,  0.2541]],\n",
      "       requires_grad=True)\n",
      "layer3.bias Parameter containing:\n",
      "tensor([-0.3215], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Evaluation\n",
    "Now that we have trained the model, we have to check if these learned weights are actually correct.\n",
    "\n",
    "In this case, a good evaluation metric is the accuracy.\n",
    "\n",
    "### 2.1.1 Accuracy\n",
    "Accuracy is the percentage of correct predictions made by a model out of all the predictions it made.\n",
    "\n",
    "Accuracy = $\\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}$\n",
    "\n",
    "<hr>\n",
    "\n",
    "## 2.1 Valutazione\n",
    "\n",
    "Ora che abbiamo addestrato il modello, dobbiamo verificare se i pesi appresi sono effettivamente corretti.\n",
    "\n",
    "In questo caso, una buona metrica di valutazione è l'accuratezza.\n",
    "\n",
    "### 2.1.1 Accuratezza\n",
    "\n",
    "L'accuratezza è la percentuale di predizioni corrette fatte da un modello rispetto a tutte le predizioni effettuate.\n",
    "\n",
    "Accuratezza = $\\frac{\\text{Numero di Predizioni Corrette}}{\\text{Numero Totale di Predizioni}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    predictions = model(X).round()\n",
    "    accuracy = (predictions.eq(y).sum().float() / y.size(0)).item()\n",
    "    print(f'\\nAccuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Interpreting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions:\n",
      "[0.0, 0.0] -> Predicted: NOT AND\n",
      "[0.0, 1.0] -> Predicted: NOT AND\n",
      "[1.0, 0.0] -> Predicted: NOT AND\n",
      "[1.0, 1.0] -> Predicted: AND\n"
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "print(\"\\nPredictions:\")\n",
    "for i in range(len(X)):\n",
    "    pred = predictions[i].item()\n",
    "    op = 'AND' if pred == 1 else 'NOT AND'\n",
    "    print(f\"{X[i].tolist()} -> Predicted: {op}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ?.1 Exercise\n",
    "Try to modify the model so that it still performs at 100% accuracy, using less layers and weights\n",
    "\n",
    "<hr>\n",
    "\n",
    "# ?.1 Esercizio\n",
    "Prova a modificare il modello in modo che continui a ottenere un'accuratezza del 100%, utilizzando meno layer e pesi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Extract the learned weights and bias\\nw1, w2 = model.layer.weight[0].detach().numpy()\\nb = model.layer.bias[0].detach().numpy()\\n# Plot the points\\nplt.figure(figsize=(6, 6))\\ncolors = ['red' if label == 0 else 'blue' for label in y.numpy().flatten()]\\nplt.scatter(X[:, 0], X[:, 1], c=colors, s=100, edgecolors='k', label='Data Points')\\n\\n# Plot the learned decision boundary\\nx1 = np.linspace(-0.5, 1.5, 100)\\nx2 = -(w2 * x1 + b) / w1\\nplt.plot(x1, x2, label='Decision Boundary', color='green')\\nx2 = -(w1 * x1 + b) / w2\\nplt.plot(x1, x2, label='Decision Boundary', color='red')\\n\\n# Formatting\\nplt.xlim(-0.2, 1.2)\\nplt.ylim(-0.2, 1.2)\\nplt.axhline(0, color='black', linestyle='--', linewidth=1)\\nplt.axvline(0, color='black', linestyle='--', linewidth=1)\\nplt.xlabel('x1')\\nplt.ylabel('x2')\\nplt.title('AND Perceptron Learned Decision Boundary')\\nplt.legend()\\nplt.grid(True)\\n\\nplt.show()'\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Extract the learned weights and bias\n",
    "w1, w2 = model.layer.weight[0].detach().numpy()\n",
    "b = model.layer.bias[0].detach().numpy()\n",
    "# Plot the points\n",
    "plt.figure(figsize=(6, 6))\n",
    "colors = ['red' if label == 0 else 'blue' for label in y.numpy().flatten()]\n",
    "plt.scatter(X[:, 0], X[:, 1], c=colors, s=100, edgecolors='k', label='Data Points')\n",
    "\n",
    "# Plot the learned decision boundary\n",
    "x1 = np.linspace(-0.5, 1.5, 100)\n",
    "x2 = -(w2 * x1 + b) / w1\n",
    "plt.plot(x1, x2, label='Decision Boundary', color='green')\n",
    "x2 = -(w1 * x1 + b) / w2\n",
    "plt.plot(x1, x2, label='Decision Boundary', color='red')\n",
    "\n",
    "# Formatting\n",
    "plt.xlim(-0.2, 1.2)\n",
    "plt.ylim(-0.2, 1.2)\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.axvline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('AND Perceptron Learned Decision Boundary')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()'\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lis-1lWkbulZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
